{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "# from picamera2 import Picamera2\n",
    "import time\n",
    "import cv2\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pose(image, landmarks):\n",
    "\t''' \n",
    "\tTODO Task 1\n",
    "\t\n",
    "\tCode to this fucntion to draw circles on the landmarks and lines\n",
    "\tconnecting the landmarks then return the image.\n",
    "\t\n",
    "\tUse the cv2.line and cv2.circle functions.\n",
    "\n",
    "\tlandmarks is a collection of 33 dictionaries with the following keys\n",
    "\t\tx: float values in the interval of [0.0,1.0]\n",
    "\t\ty: float values in the interval of [0.0,1.0]\n",
    "\t\tz: float values in the interval of [0.0,1.0]\n",
    "\t\tvisibility: float values in the interval of [0.0,1.0]\n",
    "\t\t\n",
    "\tReferences:\n",
    "\thttps://docs.opencv.org/4.x/dc/da5/tutorial_py_drawing_functions.html\n",
    "\thttps://developers.google.com/mediapipe/solutions/vision/pose_landmarker\n",
    "\t'''\n",
    "\n",
    "\t# copy the image\n",
    "\tlandmark_image = image.copy()\n",
    "\t\n",
    "\t# get the dimensions of the image\n",
    "\theight, width, _ = image.shape\n",
    "\n",
    "\t# landmarks_list = landmarks.pose_landmarks\n",
    "\n",
    "\tmp_drawing.draw_landmarks(\n",
    "        landmark_image,\n",
    "        landmarks.pose_landmarks,\n",
    "        mp_pose.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "\t\n",
    "\t\n",
    "\treturn landmark_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718086704.451802  192823 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1718086704.454524  192977 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics 630 (CFL GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1718086704.540855  192954 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1718086704.563210  192953 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "/home/renc/.local/lib/python3.10/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "pose_landmarks",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m results \u001b[38;5;241m=\u001b[39m pose\u001b[38;5;241m.\u001b[39mprocess(image)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     result_image \u001b[38;5;241m=\u001b[39m \u001b[43mdraw_pose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpose_landmarks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.png\u001b[39m\u001b[38;5;124m'\u001b[39m, result_image)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(results\u001b[38;5;241m.\u001b[39mpose_landmarks)\n",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m, in \u001b[0;36mdraw_pose\u001b[0;34m(image, landmarks)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# get the dimensions of the image\u001b[39;00m\n\u001b[1;32m     25\u001b[0m height, width, _ \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 27\u001b[0m landmarks_list \u001b[38;5;241m=\u001b[39m \u001b[43mlandmarks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpose_landmarks\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(landmarks)):\n\u001b[1;32m     30\u001b[0m \tpose_landmarks \u001b[38;5;241m=\u001b[39m landmarks[i]\n",
      "\u001b[0;31mAttributeError\u001b[0m: pose_landmarks"
     ]
    }
   ],
   "source": [
    "# Create a pose estimation model \n",
    "mp_pose = mp.solutions.pose\n",
    "\t\n",
    "# start detecting the poses\n",
    "with mp_pose.Pose(\n",
    "\t    min_detection_confidence=0.5,\n",
    "\t    min_tracking_confidence=0.5) as pose:\n",
    "\t\t\n",
    "        # load test image\n",
    "        image = cv2.imread(\"person.png\")\n",
    "\t\t\n",
    "        # To improve performance, optionally mark the image as not \n",
    "        # writeable to pass by reference.\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # get the landmarks\n",
    "        results = pose.process(image)\n",
    "\t\t\n",
    "        if results.pose_landmarks != None:\n",
    "            result_image = draw_pose(image, results.pose_landmarks)\n",
    "            cv2.imwrite('output.png', result_image)\n",
    "            print(results.pose_landmarks)\n",
    "        else:\n",
    "            print('No Pose Detected')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
